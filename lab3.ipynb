{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт необходимых библиотек\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Загрузка данных для Titanic и House Prices\n",
    "def load_and_preprocess_titanic(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    data['Age'].fillna(data['Age'].median(), inplace=True)\n",
    "    data['Fare'].fillna(data['Fare'].median(), inplace=True)\n",
    "    data.dropna(subset=['Embarked'], inplace=True)\n",
    "    data = pd.get_dummies(data, columns=['Sex', 'Embarked'])\n",
    "    features = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\n",
    "    X = data[features]\n",
    "    y = data['Survived']\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def load_and_preprocess_house_data(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    data['LotFrontage'].fillna(data['LotFrontage'].median(), inplace=True)\n",
    "    data = pd.get_dummies(data)\n",
    "    features = ['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', '1stFlrSF']\n",
    "    X = data[features]\n",
    "    y = data['SalePrice']\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Загрузка и разделение данных\n",
    "X_train_titanic, X_test_titanic, y_train_titanic, y_test_titanic = load_and_preprocess_titanic('titanic/train.csv')\n",
    "X_train_house, X_test_house, y_train_house, y_test_house = load_and_preprocess_house_data('house-prices-advanced-regression-techniques/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier - Titanic Dataset:\n",
      "Accuracy: 0.7415730337078652\n",
      "Precision: 0.6455696202531646\n",
      "Recall: 0.7391304347826086\n",
      "F1 Score: 0.6891891891891891\n"
     ]
    }
   ],
   "source": [
    "# Обучение модели Decision Tree для Titanic\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train_titanic, y_train_titanic)\n",
    "\n",
    "# Предсказания\n",
    "y_pred_titanic = clf.predict(X_test_titanic)\n",
    "\n",
    "# Оценка качества модели\n",
    "print(\"Decision Tree Classifier - Titanic Dataset:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_titanic, y_pred_titanic))\n",
    "print(\"Precision:\", precision_score(y_test_titanic, y_pred_titanic))\n",
    "print(\"Recall:\", recall_score(y_test_titanic, y_pred_titanic))\n",
    "print(\"F1 Score:\", f1_score(y_test_titanic, y_pred_titanic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Regressor - House Prices Dataset:\n",
      "Mean Absolute Error (MAE): 25180.48595890411\n",
      "Mean Squared Error (MSE): 1256737448.1441362\n",
      "Root Mean Squared Error (RMSE): 35450.49291821111\n",
      "R-squared (R²): 0.8361559320688906\n"
     ]
    }
   ],
   "source": [
    "# Обучение модели Decision Tree для House Prices\n",
    "regr = DecisionTreeRegressor(random_state=42)\n",
    "regr.fit(X_train_house, y_train_house)\n",
    "\n",
    "# Предсказания\n",
    "y_pred_house = regr.predict(X_test_house)\n",
    "\n",
    "# Оценка качества модели\n",
    "print(\"\\nDecision Tree Regressor - House Prices Dataset:\")\n",
    "print(\"Mean Absolute Error (MAE):\", mean_absolute_error(y_test_house, y_pred_house))\n",
    "print(\"Mean Squared Error (MSE):\", mean_squared_error(y_test_house, y_pred_house))\n",
    "print(\"Root Mean Squared Error (RMSE):\", np.sqrt(mean_squared_error(y_test_house, y_pred_house)))\n",
    "print(\"R-squared (R²):\", r2_score(y_test_house, y_pred_house))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Decision Tree Classifier: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "# Гипотеза 1: Тщательный препроцессинг\n",
    "def preprocess_titanic_data_extended(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    # Заполнение пропусков более интеллектуальным методом\n",
    "    data['Age'].fillna(data.groupby('Pclass')['Age'].transform('median'), inplace=True)\n",
    "    data['Fare'].fillna(data['Fare'].median(), inplace=True)\n",
    "    data.dropna(subset=['Embarked'], inplace=True)\n",
    "    # Предположим, что Cabin было заменено, если неизвестно\n",
    "    data['Cabin'] = data['Cabin'].apply(lambda x: 0 if pd.isna(x) else 1)\n",
    "    data = pd.get_dummies(data, columns=['Sex', 'Embarked'])\n",
    "    # Лог-преобразование Fare\n",
    "    data['Fare'] = np.log1p(data['Fare'])\n",
    "    features = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'Cabin']\n",
    "    X = data[features]\n",
    "    y = data['Survived']\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Обновляем данные для Titanic\n",
    "X_train_titanic_ext, X_test_titanic_ext, y_train_titanic_ext, y_test_titanic_ext = preprocess_titanic_data_extended('titanic/train.csv')\n",
    "\n",
    "# Гипотеза 4: Подбор гиперпараметров\n",
    "param_grid_classifier = {\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "grid_clf = GridSearchCV(clf, param_grid_classifier, cv=5, scoring='accuracy')\n",
    "grid_clf.fit(X_train_titanic_ext, y_train_titanic_ext)\n",
    "\n",
    "print(\"Best parameters for Decision Tree Classifier:\", grid_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Decision Tree Regressor: {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "def preprocess_house_data_extended(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    data['LotFrontage'].fillna(data['LotFrontage'].median(), inplace=True)\n",
    "    # Лог-преобразование SalePrice\n",
    "    data['SalePrice'] = np.log1p(data['SalePrice'])\n",
    "    data = pd.get_dummies(data)\n",
    "    features = ['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', '1stFlrSF']\n",
    "    X = data[features]\n",
    "    y = data['SalePrice']\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Обновляем данные для House Prices\n",
    "X_train_house_ext, X_test_house_ext, y_train_house_ext, y_test_house_ext = preprocess_house_data_extended('house-prices-advanced-regression-techniques/train.csv')\n",
    "\n",
    "param_grid_regressor = {\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "regr = DecisionTreeRegressor(random_state=42)\n",
    "grid_regr = GridSearchCV(regr, param_grid_regressor, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_regr.fit(X_train_house_ext, y_train_house_ext)\n",
    "\n",
    "print(\"Best parameters for Decision Tree Regressor:\", grid_regr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Improved Decision Tree Classifier - Titanic Dataset:\n",
      "Accuracy: 0.7865168539325843\n",
      "Precision: 0.7384615384615385\n",
      "Recall: 0.6956521739130435\n",
      "F1 Score: 0.7164179104477613\n",
      "\n",
      "Improved Decision Tree Regressor - House Prices Dataset:\n",
      "Mean Absolute Error (MAE): 0.14482998825841226\n",
      "Mean Squared Error (MSE): 0.04099732501375583\n",
      "Root Mean Squared Error (RMSE): 0.20247796179771227\n",
      "R-squared (R²): 0.7803059438046104\n"
     ]
    }
   ],
   "source": [
    "# Обучение и оценка улучшенной модели Decision Tree для Titanic\n",
    "best_clf = grid_clf.best_estimator_\n",
    "y_pred_titanic_ext = best_clf.predict(X_test_titanic_ext)\n",
    "\n",
    "print(\"\\nImproved Decision Tree Classifier - Titanic Dataset:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_titanic_ext, y_pred_titanic_ext))\n",
    "print(\"Precision:\", precision_score(y_test_titanic_ext, y_pred_titanic_ext))\n",
    "print(\"Recall:\", recall_score(y_test_titanic_ext, y_pred_titanic_ext))\n",
    "print(\"F1 Score:\", f1_score(y_test_titanic_ext, y_pred_titanic_ext))\n",
    "\n",
    "# Обучение и оценка улучшенной модели Decision Tree для House Prices\n",
    "best_regr = grid_regr.best_estimator_\n",
    "y_pred_house_ext = best_regr.predict(X_test_house_ext)\n",
    "\n",
    "print(\"\\nImproved Decision Tree Regressor - House Prices Dataset:\")\n",
    "print(\"Mean Absolute Error (MAE):\", mean_absolute_error(y_test_house_ext, y_pred_house_ext))\n",
    "print(\"Mean Squared Error (MSE):\", mean_squared_error(y_test_house_ext, y_pred_house_ext))\n",
    "print(\"Root Mean Squared Error (RMSE):\", np.sqrt(mean_squared_error(y_test_house_ext, y_pred_house_ext)))\n",
    "print(\"R-squared (R²):\", r2_score(y_test_house_ext, y_pred_house_ext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class SimpleDecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.tree = self._build_tree(X, y, depth=0)\n",
    "\n",
    "    def _build_tree(self, X, y, depth):\n",
    "        if (self.max_depth is not None and depth >= self.max_depth) or len(set(y)) == 1:\n",
    "            return self._create_leaf(y)\n",
    "\n",
    "        feature, threshold = self._find_best_split(X, y)\n",
    "        if feature is None:\n",
    "            return self._create_leaf(y)\n",
    "\n",
    "        left_indices = X[:, feature] <= threshold\n",
    "        right_indices = X[:, feature] > threshold\n",
    "\n",
    "        left_tree = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "        right_tree = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "\n",
    "        return feature, threshold, left_tree, right_tree\n",
    "\n",
    "    def _find_best_split(self, X, y):\n",
    "        best_gini = float('inf')\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "\n",
    "        for feature in range(X.shape[1]):\n",
    "            thresholds, ginis = self._calculate_gini_index(X[:, feature], y)\n",
    "            if ginis:\n",
    "                min_gini = min(ginis)\n",
    "                if min_gini < best_gini:\n",
    "                    best_gini = min_gini\n",
    "                    best_feature = feature\n",
    "                    best_threshold = thresholds[ginis.index(min_gini)]\n",
    "\n",
    "        return best_feature, best_threshold\n",
    "\n",
    "    def _calculate_gini_index(self, feature, y):\n",
    "        thresholds = sorted(set(feature))\n",
    "        ginis = []\n",
    "\n",
    "        for threshold in thresholds:\n",
    "            left_indices = feature <= threshold\n",
    "            right_indices = feature > threshold\n",
    "\n",
    "            left_gini = self._gini(y[left_indices])\n",
    "            right_gini = self._gini(y[right_indices])\n",
    "            weighted_gini = (left_gini * sum(left_indices) + right_gini * sum(right_indices)) / len(y)\n",
    "\n",
    "            ginis.append(weighted_gini)\n",
    "\n",
    "        return thresholds, ginis\n",
    "\n",
    "    def _gini(self, y):\n",
    "        proportions = [np.sum(y == c) / len(y) for c in np.unique(y)]\n",
    "        return 1 - sum([p**2 for p in proportions])\n",
    "\n",
    "    def _create_leaf(self, y):\n",
    "        return Counter(y).most_common(1)[0][0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return [self._predict_single(instance, self.tree) for instance in X]\n",
    "\n",
    "    def _predict_single(self, instance, node):\n",
    "        if isinstance(node, (np.integer, int)):\n",
    "            return node\n",
    "        feature, threshold, left_tree, right_tree = node\n",
    "        if instance[feature] <= threshold:\n",
    "            return self._predict_single(instance, left_tree)\n",
    "        else:\n",
    "            return self._predict_single(instance, right_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDecisionTreeRegressor:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.tree = self._build_tree(X, y, depth=0)\n",
    "\n",
    "    def _build_tree(self, X, y, depth):\n",
    "        if (self.max_depth is not None and depth >= self.max_depth) or len(set(y)) == 1:\n",
    "            return np.mean(y)\n",
    "\n",
    "        feature, threshold = self._find_best_split(X, y)\n",
    "        if feature is None:\n",
    "            return np.mean(y)\n",
    "\n",
    "        left_indices = X[:, feature] <= threshold\n",
    "        right_indices = X[:, feature] > threshold\n",
    "\n",
    "        left_tree = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "        right_tree = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "\n",
    "        return feature, threshold, left_tree, right_tree\n",
    "\n",
    "    def _find_best_split(self, X, y):\n",
    "        best_mse = float('inf')\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "\n",
    "        for feature in range(X.shape[1]):\n",
    "            thresholds, mses = self._calculate_mse_split(X[:, feature], y)\n",
    "            if mses:\n",
    "                min_mse = min(mses)\n",
    "                if min_mse < best_mse:\n",
    "                    best_mse = min_mse\n",
    "                    best_feature = feature\n",
    "                    best_threshold = thresholds[mses.index(min_mse)]\n",
    "\n",
    "        return best_feature, best_threshold\n",
    "\n",
    "    def _calculate_mse_split(self, feature, y):\n",
    "        thresholds = sorted(set(feature))\n",
    "        mses = []\n",
    "\n",
    "        for threshold in thresholds:\n",
    "            left_indices = feature <= threshold\n",
    "            right_indices = feature > threshold\n",
    "\n",
    "            left_mse = self._mse(y[left_indices])\n",
    "            right_mse = self._mse(y[right_indices])\n",
    "            weighted_mse = (left_mse * sum(left_indices) + right_mse * sum(right_indices)) / len(y)\n",
    "\n",
    "            mses.append(weighted_mse)\n",
    "\n",
    "        return thresholds, mses\n",
    "\n",
    "    def _mse(self, y):\n",
    "        mean = np.mean(y)\n",
    "        return np.mean((y - mean) ** 2)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return [self._predict_single(instance, self.tree) for instance in X]\n",
    "\n",
    "    def _predict_single(self, instance, node):\n",
    "        if isinstance(node, (np.float32, np.float64, float)):\n",
    "            return node\n",
    "        feature, threshold, left_tree, right_tree = node\n",
    "        if instance[feature] <= threshold:\n",
    "            return self._predict_single(instance, left_tree)\n",
    "        else:\n",
    "            return self._predict_single(instance, right_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/botashev/mult/env/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/botashev/mult/env/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# Обучение самописной модели Decision Tree для Titanic\n",
    "simple_clf = SimpleDecisionTreeClassifier(max_depth=3)\n",
    "simple_clf.fit(X_train_titanic.values, y_train_titanic.values)\n",
    "y_pred_titanic_simple = simple_clf.predict(X_test_titanic.values)\n",
    "\n",
    "# Обучение самописной модели Decision Tree для House Prices\n",
    "simple_regr = SimpleDecisionTreeRegressor(max_depth=3)\n",
    "simple_regr.fit(X_train_house.values, y_train_house.values)\n",
    "y_pred_house_simple = simple_regr.predict(X_test_house.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Decision Tree Classifier - Titanic Dataset:\n",
      "Accuracy: 0.8202247191011236\n",
      "Precision: 0.7605633802816901\n",
      "Recall: 0.782608695652174\n",
      "F1 Score: 0.7714285714285714\n",
      "\n",
      "Simple Decision Tree Regressor - House Prices Dataset:\n",
      "Mean Absolute Error (MAE): 30274.09226166296\n",
      "Mean Squared Error (MSE): 1986959536.6803293\n",
      "Root Mean Squared Error (RMSE): 44575.324302581685\n",
      "R-squared (R²): 0.7409550150789492\n"
     ]
    }
   ],
   "source": [
    "print(\"Simple Decision Tree Classifier - Titanic Dataset:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_titanic, y_pred_titanic_simple))\n",
    "print(\"Precision:\", precision_score(y_test_titanic, y_pred_titanic_simple))\n",
    "print(\"Recall:\", recall_score(y_test_titanic, y_pred_titanic_simple))\n",
    "print(\"F1 Score:\", f1_score(y_test_titanic, y_pred_titanic_simple))\n",
    "\n",
    "print(\"\\nSimple Decision Tree Regressor - House Prices Dataset:\")\n",
    "print(\"Mean Absolute Error (MAE):\", mean_absolute_error(y_test_house, y_pred_house_simple))\n",
    "print(\"Mean Squared Error (MSE):\", mean_squared_error(y_test_house, y_pred_house_simple))\n",
    "print(\"Root Mean Squared Error (RMSE):\", np.sqrt(mean_squared_error(y_test_house, y_pred_house_simple)))\n",
    "print(\"R-squared (R²):\", r2_score(y_test_house, y_pred_house_simple))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используем функции улучшенной предобработки из пункта 3\n",
    "X_train_titanic_ext, X_test_titanic_ext, y_train_titanic_ext, y_test_titanic_ext = preprocess_titanic_data_extended('titanic/train.csv')\n",
    "X_train_house_ext, X_test_house_ext, y_train_house_ext, y_test_house_ext = preprocess_house_data_extended('house-prices-advanced-regression-techniques/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем улучшенную самописную модель Decision Tree для Titanic\n",
    "improved_simple_clf = SimpleDecisionTreeClassifier(max_depth=5)  # Используем более глубокое дерево для улучшения.\n",
    "improved_simple_clf.fit(X_train_titanic_ext.values, y_train_titanic_ext.values)\n",
    "y_pred_titanic_improved_simple = improved_simple_clf.predict(X_test_titanic_ext.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/botashev/mult/env/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/botashev/mult/env/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# Обучаем улучшенную самописную модель Decision Tree для House Prices\n",
    "improved_simple_regr = SimpleDecisionTreeRegressor(max_depth=5)  # Используем более глубокое дерево для улучшения.\n",
    "improved_simple_regr.fit(X_train_house_ext.values, y_train_house_ext.values)\n",
    "y_pred_house_improved_simple = improved_simple_regr.predict(X_test_house_ext.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved Simple Decision Tree Classifier - Titanic Dataset:\n",
      "Accuracy: 0.797752808988764\n",
      "Precision: 0.7391304347826086\n",
      "Recall: 0.7391304347826086\n",
      "F1 Score: 0.7391304347826085\n",
      "\n",
      "Improved Simple Decision Tree Regressor - House Prices Dataset:\n",
      "Mean Absolute Error (MAE): 0.1482116937914148\n",
      "Mean Squared Error (MSE): 0.04184203682180933\n",
      "Root Mean Squared Error (RMSE): 0.2045532615770507\n",
      "R-squared (R²): 0.775779351804641\n"
     ]
    }
   ],
   "source": [
    "print(\"Improved Simple Decision Tree Classifier - Titanic Dataset:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_titanic_ext, y_pred_titanic_improved_simple))\n",
    "print(\"Precision:\", precision_score(y_test_titanic_ext, y_pred_titanic_improved_simple))\n",
    "print(\"Recall:\", recall_score(y_test_titanic_ext, y_pred_titanic_improved_simple))\n",
    "print(\"F1 Score:\", f1_score(y_test_titanic_ext, y_pred_titanic_improved_simple))\n",
    "\n",
    "print(\"\\nImproved Simple Decision Tree Regressor - House Prices Dataset:\")\n",
    "print(\"Mean Absolute Error (MAE):\", mean_absolute_error(y_test_house_ext, y_pred_house_improved_simple))\n",
    "print(\"Mean Squared Error (MSE):\", mean_squared_error(y_test_house_ext, y_pred_house_improved_simple))\n",
    "print(\"Root Mean Squared Error (RMSE):\", np.sqrt(mean_squared_error(y_test_house_ext, y_pred_house_improved_simple)))\n",
    "print(\"R-squared (R²):\", r2_score(y_test_house_ext, y_pred_house_improved_simple))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
