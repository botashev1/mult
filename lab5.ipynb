{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модели sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт необходимых библиотек\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Загрузка данных для Titanic и House Prices\n",
    "def load_and_preprocess_titanic(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    data['Age'].fillna(data['Age'].median(), inplace=True)\n",
    "    data['Fare'].fillna(data['Fare'].median(), inplace=True)\n",
    "    data.dropna(subset=['Embarked'], inplace=True)\n",
    "    data = pd.get_dummies(data, columns=['Sex', 'Embarked'])\n",
    "    features = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\n",
    "    X = data[features]\n",
    "    y = data['Survived']\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def load_and_preprocess_house_data(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    data['LotFrontage'].fillna(data['LotFrontage'].median(), inplace=True)\n",
    "    data = pd.get_dummies(data)\n",
    "    features = ['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', '1stFlrSF']\n",
    "    X = data[features]\n",
    "    y = data['SalePrice']\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Загрузка и разделение данных\n",
    "X_train_titanic, X_test_titanic, y_train_titanic, y_test_titanic = load_and_preprocess_titanic('titanic/train.csv')\n",
    "X_train_house, X_test_house, y_train_house, y_test_house = load_and_preprocess_house_data('house-prices-advanced-regression-techniques/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение модели градиентного бустинга для классификации\n",
    "gb_clf = GradientBoostingClassifier(random_state=42)\n",
    "gb_clf.fit(X_train_titanic, y_train_titanic)\n",
    "\n",
    "# Предсказания\n",
    "y_pred_titanic = gb_clf.predict(X_test_titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение модели градиентного бустинга для регрессии\n",
    "gb_regr = GradientBoostingRegressor(random_state=42)\n",
    "gb_regr.fit(X_train_house, y_train_house)\n",
    "\n",
    "# Предсказания\n",
    "y_pred_house = gb_regr.predict(X_test_house)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier - Titanic Dataset:\n",
      "Accuracy: 0.8202247191011236\n",
      "Precision: 0.7681159420289855\n",
      "Recall: 0.7681159420289855\n",
      "F1 Score: 0.7681159420289855\n",
      "\n",
      "Gradient Boosting Regressor - House Prices Dataset:\n",
      "Mean Absolute Error (MAE): 19818.465123659484\n",
      "Mean Squared Error (MSE): 871673675.420398\n",
      "Root Mean Squared Error (RMSE): 29524.120231099147\n",
      "R-squared (R²): 0.8863576786859942\n"
     ]
    }
   ],
   "source": [
    "print(\"Gradient Boosting Classifier - Titanic Dataset:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_titanic, y_pred_titanic))\n",
    "print(\"Precision:\", precision_score(y_test_titanic, y_pred_titanic))\n",
    "print(\"Recall:\", recall_score(y_test_titanic, y_pred_titanic))\n",
    "print(\"F1 Score:\", f1_score(y_test_titanic, y_pred_titanic))\n",
    "\n",
    "print(\"\\nGradient Boosting Regressor - House Prices Dataset:\")\n",
    "print(\"Mean Absolute Error (MAE):\", mean_absolute_error(y_test_house, y_pred_house))\n",
    "print(\"Mean Squared Error (MSE):\", mean_squared_error(y_test_house, y_pred_house))\n",
    "print(\"Root Mean Squared Error (RMSE):\", np.sqrt(mean_squared_error(y_test_house, y_pred_house)))\n",
    "print(\"R-squared (R²):\", r2_score(y_test_house, y_pred_house))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Улучшения бейзлайна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhanced_preprocess_titanic(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    # Интеллектуальное заполнение пропусков\n",
    "    data['Age'].fillna(data['Age'].median(), inplace=True)\n",
    "    data['Fare'].fillna(data.groupby('Pclass')['Fare'].transform('median'), inplace=True)\n",
    "    data.dropna(subset=['Embarked'], inplace=True)\n",
    "    \n",
    "    # Лог-преобразование тарифа для уменьшения воздействия выбросов\n",
    "    data['Fare'] = np.log1p(data['Fare'])\n",
    "\n",
    "    # Кодирование категориальных признаков с использованием get_dummies\n",
    "    data = pd.get_dummies(data, columns=['Sex', 'Embarked'])\n",
    "\n",
    "    features = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\n",
    "    X = data[features]\n",
    "    y = data['Survived']\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def enhanced_preprocess_house(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    # Интеллектуальное заполнение пропусков\n",
    "    data['LotFrontage'].fillna(data.groupby('Neighborhood')['LotFrontage'].transform('median'), inplace=True)\n",
    "\n",
    "    # Лог-преобразование целевой переменной\n",
    "    data['SalePrice'] = np.log1p(data['SalePrice'])\n",
    "\n",
    "    important_features = ['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', '1stFlrSF']\n",
    "    data = pd.get_dummies(data)\n",
    "    X = data[important_features]\n",
    "    y = data['SalePrice']\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Gradient Boosting Classifier: {'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_clf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "grid_clf = GridSearchCV(estimator=GradientBoostingClassifier(random_state=42), param_grid=param_grid_clf, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_clf.fit(X_train_titanic, y_train_titanic)\n",
    "\n",
    "print(\"Best parameters for Gradient Boosting Classifier:\", grid_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение улучшенной модели градиентного бустинга для Titanic\n",
    "improved_gb_clf = GradientBoostingClassifier(**grid_clf.best_params_, random_state=42)\n",
    "improved_gb_clf.fit(X_train_titanic, y_train_titanic)\n",
    "y_pred_titanic_improved = improved_gb_clf.predict(X_test_titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/botashev/mult/env/lib/python3.7/site-packages/sklearn/model_selection/_search.py:296: UserWarning: The total space of parameters 36 is smaller than n_iter=100. Running 36 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid_regr = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "grid_regr = RandomizedSearchCV(estimator=GradientBoostingRegressor(random_state=42), param_distributions=param_grid_regr, cv=5, n_jobs=-1, scoring='neg_mean_squared_error', n_iter=100, random_state=42)\n",
    "grid_regr.fit(X_train_house, y_train_house)\n",
    "\n",
    "improved_gb_regr = GradientBoostingRegressor(**grid_regr.best_params_, random_state=42)\n",
    "improved_gb_regr.fit(X_train_house, y_train_house)\n",
    "y_pred_house_improved = improved_gb_regr.predict(X_test_house)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved Gradient Boosting Classifier - Titanic Dataset:\n",
      "Accuracy: 0.8146067415730337\n",
      "Precision: 0.7903225806451613\n",
      "Recall: 0.7101449275362319\n",
      "F1 Score: 0.7480916030534351\n",
      "\n",
      "Improved Gradient Boosting Regressor - House Prices Dataset:\n",
      "Mean Absolute Error (MAE): 21485.396079199447\n",
      "Mean Squared Error (MSE): 1010335655.8718059\n",
      "Root Mean Squared Error (RMSE): 31785.77757223828\n",
      "R-squared (R²): 0.8682799624708115\n"
     ]
    }
   ],
   "source": [
    "print(\"Improved Gradient Boosting Classifier - Titanic Dataset:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_titanic, y_pred_titanic_improved))\n",
    "print(\"Precision:\", precision_score(y_test_titanic, y_pred_titanic_improved))\n",
    "print(\"Recall:\", recall_score(y_test_titanic, y_pred_titanic_improved))\n",
    "print(\"F1 Score:\", f1_score(y_test_titanic, y_pred_titanic_improved))\n",
    "\n",
    "print(\"\\nImproved Gradient Boosting Regressor - House Prices Dataset:\")\n",
    "print(\"Mean Absolute Error (MAE):\", mean_absolute_error(y_test_house, y_pred_house_improved))\n",
    "print(\"Mean Squared Error (MSE):\", mean_squared_error(y_test_house, y_pred_house_improved))\n",
    "print(\"Root Mean Squared Error (RMSE):\", np.sqrt(mean_squared_error(y_test_house, y_pred_house_improved)))\n",
    "print(\"R-squared (R²):\", r2_score(y_test_house, y_pred_house_improved))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собственная имплементация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "class SimpleGradientBoostingClassifier:\n",
    "    def __init__(self, n_estimators=10, learning_rate=0.1, max_depth=3):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.models = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Инициализируем модели\n",
    "        y_pred = np.zeros(shape=y.shape)\n",
    "        \n",
    "        for _ in range(self.n_estimators):\n",
    "            # Вычисляем остатки\n",
    "            residual = y - 1 / (1 + np.exp(-y_pred))\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            tree.fit(X, residual)\n",
    "            y_pred += self.learning_rate * tree.predict(X)\n",
    "            self.models.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = np.zeros(shape=(X.shape[0],))\n",
    "        for tree in self.models:\n",
    "            y_pred += self.learning_rate * tree.predict(X)\n",
    "        return (y_pred > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGradientBoostingRegressor:\n",
    "    def __init__(self, n_estimators=10, learning_rate=0.1, max_depth=3):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.models = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Инициализация\n",
    "        residual = y\n",
    "        for _ in range(self.n_estimators):\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            tree.fit(X, residual)\n",
    "            prediction = tree.predict(X)\n",
    "            residual -= self.learning_rate * prediction\n",
    "            self.models.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = np.zeros(shape=(X.shape[0],))\n",
    "        for tree in self.models:\n",
    "            y_pred += self.learning_rate * tree.predict(X)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение простого градиентного бустинга для классификации\n",
    "simple_gb_clf = SimpleGradientBoostingClassifier(n_estimators=10, learning_rate=0.1, max_depth=3)\n",
    "simple_gb_clf.fit(X_train_titanic, y_train_titanic)\n",
    "y_pred_titanic_simple = simple_gb_clf.predict(X_test_titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение простого градиентного бустинга для регрессии\n",
    "simple_gb_regr = SimpleGradientBoostingRegressor(n_estimators=10, learning_rate=0.1, max_depth=3)\n",
    "simple_gb_regr.fit(X_train_house, y_train_house)\n",
    "y_pred_house_simple = simple_gb_regr.predict(X_test_house)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Gradient Boosting Classifier - Titanic Dataset:\n",
      "Accuracy: 0.6123595505617978\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 Score: 0.0\n",
      "\n",
      "Simple Gradient Boosting Regressor - House Prices Dataset:\n",
      "Mean Absolute Error (MAE): 64244.727409513325\n",
      "Mean Squared Error (MSE): 6557324943.750704\n",
      "Root Mean Squared Error (RMSE): 80977.31128995765\n",
      "R-squared (R²): 0.14510481475918646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/botashev/mult/env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Simple Gradient Boosting Classifier - Titanic Dataset:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_titanic, y_pred_titanic_simple))\n",
    "print(\"Precision:\", precision_score(y_test_titanic, y_pred_titanic_simple))\n",
    "print(\"Recall:\", recall_score(y_test_titanic, y_pred_titanic_simple))\n",
    "print(\"F1 Score:\", f1_score(y_test_titanic, y_pred_titanic_simple))\n",
    "\n",
    "print(\"\\nSimple Gradient Boosting Regressor - House Prices Dataset:\")\n",
    "print(\"Mean Absolute Error (MAE):\", mean_absolute_error(y_test_house, y_pred_house_simple))\n",
    "print(\"Mean Squared Error (MSE):\", mean_squared_error(y_test_house, y_pred_house_simple))\n",
    "print(\"Root Mean Squared Error (RMSE):\", np.sqrt(mean_squared_error(y_test_house, y_pred_house_simple)))\n",
    "print(\"R-squared (R²):\", r2_score(y_test_house, y_pred_house_simple))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Улучшения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Пример использования стандартизации\n",
    "scaler = StandardScaler()\n",
    "X_train_titanic_scaled = scaler.fit_transform(X_train_titanic)\n",
    "X_test_titanic_scaled = scaler.transform(X_test_titanic)\n",
    "\n",
    "# Для регрессии\n",
    "X_train_house_scaled = scaler.fit_transform(X_train_house)\n",
    "X_test_house_scaled = scaler.transform(X_test_house)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedGradientBoostingClassifier:\n",
    "    def __init__(self, n_estimators=10, learning_rate=0.1, max_depth=3):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.models = []\n",
    "        self.init_val = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Use log(odds) transformation for better initialization\n",
    "        y_mean = np.mean(y)\n",
    "        y_pred = np.full(y.shape, np.log(y_mean / (1 - y_mean)))\n",
    "        self.init_val = y_pred[0]\n",
    "        \n",
    "        for _ in range(self.n_estimators):\n",
    "            probs = 1 / (1 + np.exp(-y_pred))\n",
    "            residual = y - probs\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            tree.fit(X, residual)\n",
    "            y_pred += self.learning_rate * tree.predict(X)\n",
    "            self.models.append(tree)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = np.full(X.shape[0], self.init_val)\n",
    "        for tree in self.models:\n",
    "            y_pred += self.learning_rate * tree.predict(X)\n",
    "        return (1 / (1 + np.exp(-y_pred)) > 0.5).astype(int)\n",
    "\n",
    "# Обучение и предсказание\n",
    "improved_simple_gb_clf = ImprovedGradientBoostingClassifier(n_estimators=10, learning_rate=0.1, max_depth=3)\n",
    "improved_simple_gb_clf.fit(X_train_titanic_scaled, y_train_titanic)\n",
    "y_pred_titanic_improved = improved_simple_gb_clf.predict(X_test_titanic_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedGradientBoostingRegressor:\n",
    "    def __init__(self, n_estimators=10, learning_rate=0.1, max_depth=3):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.models = []\n",
    "        self.init_val = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        y_pred = np.full(y.shape, np.mean(y))\n",
    "        self.init_val = y_pred[0]\n",
    "        \n",
    "        residual = y\n",
    "        for _ in range(self.n_estimators):\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            tree.fit(X, residual)\n",
    "            prediction = tree.predict(X)\n",
    "            residual -= self.learning_rate * prediction\n",
    "            y_pred += self.learning_rate * prediction\n",
    "            self.models.append(tree)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = np.full(X.shape[0], self.init_val)\n",
    "        for tree in self.models:\n",
    "            y_pred += self.learning_rate * tree.predict(X)\n",
    "        return y_pred\n",
    "\n",
    "# Обучение и предсказание\n",
    "improved_simple_gb_regr = ImprovedGradientBoostingRegressor(n_estimators=10, learning_rate=0.1, max_depth=3)\n",
    "improved_simple_gb_regr.fit(X_train_house_scaled, y_train_house)\n",
    "y_pred_house_improved = improved_simple_gb_regr.predict(X_test_house_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved Simple Gradient Boosting Classifier - Titanic Dataset:\n",
      "Accuracy: 0.7359550561797753\n",
      "Precision: 0.9230769230769231\n",
      "Recall: 0.34782608695652173\n",
      "F1 Score: 0.5052631578947369\n",
      "\n",
      "Improved Simple Gradient Boosting Regressor - House Prices Dataset:\n",
      "Mean Absolute Error (MAE): 77277.49204817129\n",
      "Mean Squared Error (MSE): 10662828698.649317\n",
      "Root Mean Squared Error (RMSE): 103260.97374443704\n",
      "R-squared (R²): -0.3901401857796094\n"
     ]
    }
   ],
   "source": [
    "print(\"Improved Simple Gradient Boosting Classifier - Titanic Dataset:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_titanic, y_pred_titanic_improved))\n",
    "print(\"Precision:\", precision_score(y_test_titanic, y_pred_titanic_improved))\n",
    "print(\"Recall:\", recall_score(y_test_titanic, y_pred_titanic_improved))\n",
    "print(\"F1 Score:\", f1_score(y_test_titanic, y_pred_titanic_improved))\n",
    "\n",
    "print(\"\\nImproved Simple Gradient Boosting Regressor - House Prices Dataset:\")\n",
    "print(\"Mean Absolute Error (MAE):\", mean_absolute_error(y_test_house, y_pred_house_improved))\n",
    "print(\"Mean Squared Error (MSE):\", mean_squared_error(y_test_house, y_pred_house_improved))\n",
    "print(\"Root Mean Squared Error (RMSE):\", np.sqrt(mean_squared_error(y_test_house, y_pred_house_improved)))\n",
    "print(\"R-squared (R²):\", r2_score(y_test_house, y_pred_house_improved))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
