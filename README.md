# Студент группы М80-401Б-21 Боташев Анзор

## Подведение итогов

### 1. K-Nearest Neighbors (KNN)

### Классификация:

| Модель                                        |  Accuracy | Precision | Recall | F1-score |
|:----------------------------------------------|----------:|----------:|-------:|---------:|
| Sklearn (до улучшения)                        |   62.9%   |   53.3%   |  42.9% |   47.5%  |
| Sklearn (после улучшения)                     |   66.4%   |   60.5%   |  41.1% |   48.9%  |
| Собственная имплементация (до улучшения)      |   62.2%   |   52.3%   |  41.1% |    46%   |
| Собственная имплементация (после улучшения)   |   63.6%   |   54.8%   |  41.1% |   46.9%  |

### Регрессия:

| Модель                                        |     MAE   |       MSE      |   $R^2$ |
|:----------------------------------------------|----------:|---------------:|--------:|
| Sklearn (до улучшения)                        |   21665   | 1 291 465 266  |   0.832 |
| Sklearn (после улучшения)                     |   20816   | 1 126 672 963  |   0.853 |
| Собственная имплементация (до улучшения)      |   21674   | 1 291 750 751  |   0.832 |
| Собственная имплементация (после улучшения)   |   20982   | 1 089 580 748  |   0.858 |



### 2. Linear Model

### Классификация:

| Модель                                        |  Accuracy | Precision | Recall | F1-score |
|:----------------------------------------------|----------:|----------:|-------:|---------:|
| Sklearn (до улучшения)                        |   77.0%   |   68.0%   |  76.8% |  72.1%   |
| Sklearn (после улучшения)                     |   82.1%   |   80.0%   |  75.7% |  77.8%   |
| Собственная имплементация (до улучшения)      |   78.1%   |   70.3%   |  75.4% |  72.7%   |
| Собственная имплементация (после улучшения)   |   78.1%   |   70.3%   |  75.4% |  72.7%   |

### Регрессия:

| Модель                                        |     MAE   |       MSE      | $R^2$  |
|:----------------------------------------------|----------:|---------------:|-------:|
| Sklearn (до улучшения)                        |   25289   | 1591935019     |  0.79  |
| Sklearn (после улучшения)                     |   25145   | 1567149663     |  0.80  |
| Собственная имплементация (до улучшения)      |   25432   | 1596556311     |  0.79  |
| Собственная имплементация (после улучшения)   |   25432   | 1596580038     |  0.79  |


### 3. Decision Tree

### Классификация:

| Модель                                        |  Accuracy | Precision | Recall | F1-score |
|:----------------------------------------------|----------:|----------:|-------:|---------:|
| Sklearn (до улучшения)                        |   74.2%   |   64.6%   |  73.9% |  68.9%   |
| Sklearn (после улучшения)                     |   78.7%   |   73.8%   |  69.6% |  71.6%   |
| Собственная имплементация (до улучшения)      |   82.0%   |   76.1%   |  78.3% |  77.1%   |
| Собственная имплементация (после улучшения)   |   79.8%   |   73.9%   |  73.9% |  73.9%   |

### Регрессия:

| Модель                                        |     MAE   |       MSE      | $R^2$  |
|:----------------------------------------------|----------:|---------------:|-------:|
| Sklearn (до улучшения)                        |   25180   | 1256737448     |  0.84  |
| Sklearn (после улучшения)                     |    0.145  |        0.041   |  0.78  |
| Собственная имплементация (до улучшения)      |   30274   | 1986959537     |  0.74  |
| Собственная имплементация (после улучшения)   |    0.148  |        0.042   |  0.78  |


### 4. Random Forest

### Классификация:

| Модель                                        |  Accuracy | Precision | Recall | F1-score |
|:----------------------------------------------|----------:|----------:|-------:|---------:|
| Sklearn (до улучшения)                        |   76.4%   |   68.0%   |  73.9% |  70.8%   |
| Sklearn (после улучшения)                     |   79.2%   |   74.2%   |  71.0% |  72.6%   |
| Собственная имплементация (до улучшения)      |   75.3%   |   65.8%   |  75.4% |  70.3%   |
| Собственная имплементация (после улучшения)   |   76.4%   |   69.0%   |  71.0% |  70.0%   |

### Регрессия:

| Модель                                        |     MAE   |       MSE      | $R^2$  |
|:----------------------------------------------|----------:|---------------:|-------:|
| Sklearn (до улучшения)                        |   19994   | 876487911      |  0.89  |
| Sklearn (после улучшения)                     |   20589   | 1081613087     |  0.86  |
| Собственная имплементация (до улучшения)      |   28740   | 1703506783     |  0.78  |
| Собственная имплементация (после улучшения)   |   25110   | 1288310921     |  0.83  |

### 5. Gradient Boosting

### Классификация:

| Модель                                        |  Accuracy | Precision | Recall | F1-score |
|:----------------------------------------------|----------:|----------:|-------:|---------:|
| Sklearn (до улучшения)                        |   82.0%   |   76.8%   |  76.8% |  76.8%   |
| Sklearn (после улучшения)                     |   81.5%   |   79.0%   |  71.0% |  74.8%   |
| Собственная имплементация (до улучшения)      |   61.2%   |    0.0%   |   0.0% |   0.0%   |
| Собственная имплементация (после улучшения)   |   73.6%   |   92.3%   |  34.8% |  50.5%   |

### Регрессия:

| Модель                                        |     MAE   |       MSE      | $R^2$  |
|:----------------------------------------------|----------:|---------------:|-------:|
| Sklearn (до улучшения)                        |   19818   | 871673675      |  0.89  |
| Sklearn (после улучшения)                     |   21485   | 1010335656     |  0.87  |
| Собственная имплементация (до улучшения)      |   64245   | 6557324944     |  0.15  |
| Собственная имплементация (после улучшения)   |   77277   | 10662828699    | 0.39  |


## Выводы

- Модели из библиотеки ```sklearn``` демонстрируют зачастую более высокие результаты по сравнению с собственными имплементациями, особенно в задачах классификации. Это свидетельствует о высокой оптимизации стандартных библиотечных решений.

- В задачах регрессии наилучшие результаты были достигнуты моделями ```KNN``` и ```Random Forest``` из ```sklearn```, что указывает на их эффективность для конкретных наборов данных.

- В задачах классификации такие модели, как ```Linear Model```, а также улучшенные версии ```Decision Tree``` и ```Random Forest``` из библиотеки ```sklearn```, показали наибольшую точность и сбалансированность по метрикам ```Precision```, ```Recall``` и ```F1-score```.

- Оптимизация гиперпараметров и другие улучшения моделей оказали значительное положительное влияние на качество всех исследуемых моделей, что подчеркивает важность настройки параметров для повышения точности и эффективности моделей машинного обучения.
